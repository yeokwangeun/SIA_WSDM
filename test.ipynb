{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwangeunyeo/anaconda/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from dataset import load_data, TrainDataset, EvalDataset\n",
    "from dataloader import DataLoaderHandler\n",
    "from model import SIA, SimpleModel\n",
    "from trainer import train, evaluate\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from einops import repeat\n",
    "\n",
    "BADEDIR = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args([])\n",
    "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args.dataset = \"amazon_beauty\"\n",
    "args.maxlen = 50\n",
    "args.batch_size = 64\n",
    "args.content = [\"image\", \"desc\"]\n",
    "args.latent_dim = 128\n",
    "args.item_num_outputs = 8\n",
    "args.item_num_heads = 8\n",
    "args.item_num_latents = 8\n",
    "args.item_dim_hidden = 64\n",
    "args.attn_depth = 5\n",
    "args.attn_self_per_cross = 2\n",
    "args.attn_dropout = 0.0\n",
    "args.attn_ff_dropout = 0.2\n",
    "args.attn_num_heads = 8\n",
    "args.attn_dim_head = 64\n",
    "args.eval_sample_mode = \"uni\"\n",
    "args.lr = 1e-3\n",
    "args.weight_decay = 0.\n",
    "args.num_epochs = 100\n",
    "args.lr_milestones = None\n",
    "args.early_stop = 5\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = \"./dataset/raw/\"\n",
    "processed_dir = \"./dataset/processed/\"\n",
    "\n",
    "inter, item_feats, pop = load_data(args, raw_dir, processed_dir, logger)\n",
    "dim_item_feats = [tuple(feat.values())[0].shape[0] for feat in item_feats]\n",
    "num_items = len(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(inter, item_feats, args, logger)\n",
    "val_dataset = EvalDataset(inter, item_feats, pop, args, logger, mode=\"val\", eval_mode=args.eval_sample_mode)\n",
    "test_dataset = EvalDataset(inter, item_feats, pop, args, logger, mode=\"test\", eval_mode=args.eval_sample_mode)\n",
    "train_loader = DataLoaderHandler(\"train\", train_dataset, args, logger).get_dataloader()\n",
    "val_loader = DataLoaderHandler(\"val\", val_dataset, args, logger).get_dataloader()\n",
    "test_loader = DataLoaderHandler(\"test\", test_dataset, args, logger).get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SIA(\n",
    "    latent_dim=args.latent_dim,\n",
    "    item_num_outputs=args.item_num_outputs,\n",
    "    item_num_heads=args.item_num_heads,\n",
    "    item_num_latents=args.item_num_latents,\n",
    "    item_dim_hidden=args.item_dim_hidden,\n",
    "    attn_depth=args.attn_depth,\n",
    "    attn_self_per_cross=args.attn_self_per_cross,\n",
    "    attn_dropout=args.attn_dropout,\n",
    "    attn_ff_dropout=args.attn_ff_dropout,\n",
    "    attn_num_heads=args.attn_num_heads,\n",
    "    attn_dim_head=args.attn_dim_head,\n",
    "    dim_item_feats=dim_item_feats,\n",
    "    num_items=num_items,\n",
    "    maxlen=args.maxlen,\n",
    "    device=args.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "milestones = args.lr_milestones if args.lr_milestones else []\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmupBeforeMultiStepLR(torch.optim.lr_scheduler.LambdaLR):\n",
    "    def __init__(self, optimizer, warmup_steps=None, milestones=None, gamma=None, last_epoch=-1):\n",
    "        self.gamma = 1\n",
    "        def lr_lambda(step):\n",
    "            if warmup_steps and step < warmup_steps:\n",
    "                return step / warmup_steps\n",
    "            if milestones and gamma and step in milestones:\n",
    "                self.gamma *= gamma\n",
    "            return self.gamma\n",
    "\n",
    "        super().__init__(optimizer, lr_lambda, last_epoch=last_epoch)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000003e-05"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(num_items=num_items, maxlen=args.maxlen, device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./saved/SIMPLE.pt\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [00:12<00:00, 45.03it/s]\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate(model, test_loader, args.eval_sample_mode, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG@1': 0.10248367504063417,\n",
       " 'NDCG@5': 0.1859364205755028,\n",
       " 'NDCG@10': 0.21774015628144958,\n",
       " 'HR@1': 0.10248367504063417,\n",
       " 'HR@5': 0.2641934472040834,\n",
       " 'HR@10': 0.36294162935926316}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 15:35:48.163737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 15:35:48.336041: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-08 15:35:49.366745: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 15:35:49.366814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 15:35:49.366822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/kwangeunyeo/anaconda/envs/py38/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "def get_writer(dataset_name):\n",
    "    log_dir = os.path.join(\"./\", f\"log_tensorboard/{dataset_name}\")\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    return writer\n",
    "\n",
    "\n",
    "model = model.to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "milestones = args.lr_milestones if args.lr_milestones else [int(args.num_epochs*0.8), int(args.num_epochs*0.9)]\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "writer = get_writer(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 11.131933212280273:   0%|          | 1/548 [00:05<48:53,  5.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m train(\n\u001b[1;32m      2\u001b[0m     args\u001b[39m.\u001b[39;49mnum_epochs, \n\u001b[1;32m      3\u001b[0m     args\u001b[39m.\u001b[39;49mearly_stop, \n\u001b[1;32m      4\u001b[0m     train_loader, \n\u001b[1;32m      5\u001b[0m     val_loader, \n\u001b[1;32m      6\u001b[0m     args\u001b[39m.\u001b[39;49meval_sample_mode,\n\u001b[1;32m      7\u001b[0m     num_items,\n\u001b[1;32m      8\u001b[0m     model, \n\u001b[1;32m      9\u001b[0m     optimizer, \n\u001b[1;32m     10\u001b[0m     scheduler, \n\u001b[1;32m     11\u001b[0m     loss_fn, \n\u001b[1;32m     12\u001b[0m     writer, \n\u001b[1;32m     13\u001b[0m     logger\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/SIA/trainer/trainer.py:32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, early_stop, train_loader, val_loader, eval_sample_mode, num_items, model, optimizer, scheduler, loss_fn, writer, logger)\u001b[0m\n\u001b[1;32m     30\u001b[0m logits \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     31\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, next_item_list)\n\u001b[0;32m---> 32\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     33\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda/envs/py38/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda/envs/py38/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(\n",
    "    args.num_epochs, \n",
    "    args.early_stop, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    args.eval_sample_mode,\n",
    "    num_items,\n",
    "    model, \n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    loss_fn, \n",
    "    writer, \n",
    "    logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3]).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 548/548 [05:06<00:00,  1.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG@1': 0.0,\n",
       " 'NDCG@5': 2.456166868033892e-05,\n",
       " 'NDCG@10': 4.138834934897614e-05,\n",
       " 'HR@1': 0.0,\n",
       " 'HR@5': 5.7030425732128093e-05,\n",
       " 'HR@10': 0.00011406085146425619}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_loader, \"uni\", num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_item_feats = [tuple(feat.values())[0].shape[0] for feat in item_feats]\n",
    "num_items = len(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SIA(\n",
    "    latent_dim=args.latent_dim,\n",
    "    item_num_outputs=args.item_num_outputs,\n",
    "    item_num_heads=args.item_num_heads,\n",
    "    item_num_latents=args.item_num_latents,\n",
    "    item_dim_hidden=args.item_dim_hidden,\n",
    "    attn_depth=args.attn_depth,\n",
    "    attn_self_per_cross=args.attn_self_per_cross,\n",
    "    attn_dropout=args.attn_dropout,\n",
    "    attn_ff_dropout=args.attn_ff_dropout,\n",
    "    attn_num_heads=args.attn_num_heads,\n",
    "    attn_dim_head=args.attn_dim_head,\n",
    "    dim_item_feats=dim_item_feats,\n",
    "    num_items=num_items,\n",
    "    maxlen=args.maxlen,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "# seq_list: (B, N)\n",
    "# next_item_list: (B,)\n",
    "# item_feat_list: (B, N, d)\n",
    "seq_list, pos_list, next_item_list, *item_feat_lists = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (seq_list, pos_list, *item_feat_lists)\n",
    "logits = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.0084, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "loss_fn(logits, next_item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "# seq_list: (B, N)\n",
    "# next_item_list: (B,)\n",
    "# item_feat_list: (B, N, d)\n",
    "seq_list, pos_list, next_item_list, candidate_list, *item_feat_lists = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (seq_list, pos_list, *item_feat_lists)\n",
    "logits = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50302])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = logits if args.eval_sample_mode == \"full\" else logits.gather(dim=1, index=candidate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = (-scores).argsort(dim=1)\n",
    "cut = rank[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_item_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_label = F.one_hot(next_item_list, num_classes=(num_items + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = one_hot_label.gather(dim=1, index=cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(2, 2 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 1 / torch.log2(position.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcg = (hits * weights).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_sum = hits.sum()\n",
    "ndcg_sum = dcg.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NDCG', 1), ('NDCG', 5), ('NDCG', 10), ('HR', 1), ('HR', 5), ('HR', 10)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(a, b) for a, b in itertools.product([\"NDCG\", \"HR\"], [1, 5, 10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arguments\n",
    "# item_feat_dims = [tuple(feat.values())[0].shape[0] for feat in item_feats]\n",
    "# n_items = len(pop)\n",
    "\n",
    "# # LAYERS\n",
    "# set_transformers = nn.ModuleList([\n",
    "#     SetTransformer(\n",
    "#         dim_input=feat_dim,\n",
    "#         num_outputs=args.item_num_outputs,\n",
    "#         dim_output=args.latent_dim,\n",
    "#         num_inds=args.item_num_latents,\n",
    "#         dim_hidden=args.item_dim_hidden,\n",
    "#         num_heads=args.item_num_heads,\n",
    "#         ln=True,\n",
    "#     ) for feat_dim in item_feat_dims\n",
    "# ])\n",
    "# id_embedding = nn.Embedding(\n",
    "#     num_embeddings=(n_items + 1),\n",
    "#     embedding_dim=args.latent_dim,\n",
    "#     device=args.device,\n",
    "#     padding_idx=0\n",
    "# )\n",
    "# pos_embedding = nn.Embedding(\n",
    "#     num_embeddings=(args.maxlen + 1),\n",
    "#     embedding_dim=args.latent_dim,\n",
    "#     device=args.device,\n",
    "#     padding_idx=0\n",
    "# )\n",
    "# # id_set_transformer = SetTransformer(\n",
    "# #     dim_input=args.emb_size,\n",
    "# #     num_outputs=16,\n",
    "# #     dim_output=args.emb_size,\n",
    "# #     num_inds=16,\n",
    "# #     dim_hidden=args.st_dim_hidden,\n",
    "# #     num_heads=args.st_num_heads,\n",
    "# #     ln=True\n",
    "# # )\n",
    "\n",
    "# get_latent_attn = lambda: PreNorm(\n",
    "#     args.latent_dim,\n",
    "#     Attention(\n",
    "#         query_dim=args.latent_dim,\n",
    "#         heads=args.attn_num_heads,\n",
    "#         dim_head=args.attn_dim_head,\n",
    "#         dropout=args.attn_dropout\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# get_cross_attn = lambda: PreNorm(\n",
    "#     args.latent_dim, \n",
    "#     Attention(\n",
    "#         query_dim=args.latent_dim,\n",
    "#         context_dim=args.latent_dim,\n",
    "#         heads=args.attn_num_heads,\n",
    "#         dim_head=args.attn_dim_head,\n",
    "#         dropout=args.attn_dropout\n",
    "#     ), \n",
    "#     context_dim=args.latent_dim\n",
    "# )\n",
    "\n",
    "# get_latent_ff = lambda: PreNorm(\n",
    "#     args.latent_dim,\n",
    "#     FeedForward(\n",
    "#         args.latent_dim, \n",
    "#         dropout=args.attn_ff_dropout\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# get_cross_ff = lambda: PreNorm(\n",
    "#     args.latent_dim,\n",
    "#     FeedForward(\n",
    "#         args.latent_dim, \n",
    "#         dropout=args.attn_ff_dropout\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# layers = nn.ModuleList([])\n",
    "# for _ in range(args.attn_depth):\n",
    "#     self_attns = nn.ModuleList([])\n",
    "#     for _ in range(args.attn_self_per_cross):\n",
    "#         self_attns.append(nn.ModuleList([\n",
    "#             get_latent_attn(),\n",
    "#             get_latent_ff(),            \n",
    "#         ]))\n",
    "#     layers.append(nn.ModuleList([\n",
    "#         get_cross_attn(),\n",
    "#         get_cross_ff(),\n",
    "#         self_attns\n",
    "#     ]))\n",
    "        \n",
    "# to_logits = nn.Sequential(\n",
    "#     Reduce('b n d -> b d', 'mean'),\n",
    "#     nn.LayerNorm(args.latent_dim),\n",
    "#     nn.Linear(args.latent_dim, n_items + 1)\n",
    "# )\n",
    "\n",
    "# # FORWARD\n",
    "\n",
    "# id_emb = id_embedding(seq_list)\n",
    "# pos_emb = pos_embedding(pos_list)\n",
    "# x = id_emb + pos_emb\n",
    "\n",
    "# item_feat = []\n",
    "# for set_transformer, item_feat_list in zip(set_transformers, item_feat_lists):\n",
    "#     out = [set_transformer(feat.unsqueeze(0)) for feat in item_feat_list]\n",
    "#     out = torch.cat(out)\n",
    "#     item_feat.append(out)\n",
    "# item_feat = torch.cat(item_feat, dim=1)\n",
    "\n",
    "# mask_latent = repeat(pos_list, 'b n -> b n d', d=args.latent_dim).float()\n",
    "# mask_items = torch.ones(item_feat.shape)\n",
    "# mask_cross_attn = einsum(\"b i d, b j d -> b i j\", mask_latent, mask_items) > 0\n",
    "# mask_self_attn = einsum(\"b i d, b j d -> b i j\", mask_latent, mask_latent) > 0\n",
    "\n",
    "# for cross_attn, cross_ff, self_attns in layers:\n",
    "#     x = cross_attn(x, context=item_feat, mask=mask_cross_attn) + x\n",
    "#     x = cross_ff(x) + x\n",
    "    \n",
    "#     for self_attn, self_ff in self_attns:\n",
    "#         x = self_attn(x, mask=mask_self_attn) + x\n",
    "#         x = self_ff(x) + x\n",
    "\n",
    "# x = to_logits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_list, pos_list, next_item_list, *item_feat_list in tqdm(train_loader):\n",
    "    id_emb = id_embedding(seq_list)\n",
    "    pos_emb = pos_embedding(pos_list)\n",
    "    x = id_emb + pos_emb\n",
    "\n",
    "    item_feat = []\n",
    "    for set_transformer, item_feat_list in zip(set_transformers, item_feat_lists):\n",
    "        out = [set_transformer(feat.unsqueeze(0)) for feat in item_feat_list]\n",
    "        out = torch.cat(out)\n",
    "        item_feat.append(out)\n",
    "    item_feat = torch.cat(item_feat, dim=1)\n",
    "\n",
    "    mask_latent = repeat(pos_list, 'b n -> b n d', d=args.latent_dim).float()\n",
    "    mask_items = torch.ones(item_feat.shape)\n",
    "    mask_cross_attn = einsum(\"b i d, b j d -> b i j\", mask_latent, mask_items) > 0\n",
    "    mask_self_attn = einsum(\"b i d, b j d -> b i j\", mask_latent, mask_latent) > 0\n",
    "\n",
    "    for cross_attn, cross_ff, self_attns in layers:\n",
    "        x = cross_attn(x, context=item_feat, mask=mask_cross_attn) + x\n",
    "        x = cross_ff(x) + x\n",
    "        \n",
    "        for self_attn, self_ff in self_attns:\n",
    "            x = self_attn(x, mask=mask_self_attn) + x\n",
    "            x = self_ff(x) + x\n",
    "\n",
    "    x = to_logits(x)\n",
    "    loss = cross_entropy(x, next_item_list)\n",
    "    loss.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bd7c0d952670d349d3c765f972615a84836b3c08a6ed5ce77d82420ec3e88ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
